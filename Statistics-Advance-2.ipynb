{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe Probability Mass Function (PMF) is used to describe the probability distribution of a discrete random variable. It gives the probability of each possible outcome. For example, if you have a fair six-sided die, the PMF would give you the probabilities of rolling each number from 1 to 6.\\n\\nThe Probability Density Function (PDF) is used to describe the probability distribution of a continuous random variable. Unlike the PMF, which deals with discrete outcomes, the PDF deals with continuous outcomes. For instance, the PDF of a standard normal distribution describes the likelihood of observing different values of a continuous variable like height'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1\n",
    "'''\n",
    "The Probability Mass Function (PMF) is used to describe the probability distribution of a discrete random variable. It gives the probability of each possible outcome. For example, if you have a fair six-sided die, the PMF would give you the probabilities of rolling each number from 1 to 6.\n",
    "\n",
    "The Probability Density Function (PDF) is used to describe the probability distribution of a continuous random variable. Unlike the PMF, which deals with discrete outcomes, the PDF deals with continuous outcomes. For instance, the PDF of a standard normal distribution describes the likelihood of observing different values of a continuous variable like height'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Cumulative Density Function (CDF) is a function that gives the probability that a random variable takes a value less than or equal to a certain value. \\nIt's the cumulative sum of probabilities up to a particular point. It's used to determine probabilities related to a range of values. For example, the CDF of a normal distribution can tell you the probability that a randomly selected observation is less than a specific value.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2\n",
    "'''The Cumulative Density Function (CDF) is a function that gives the probability that a random variable takes a value less than or equal to a certain value. \n",
    "It's the cumulative sum of probabilities up to a particular point. It's used to determine probabilities related to a range of values. For example, the CDF of a normal distribution can tell you the probability that a randomly selected observation is less than a specific value.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The normal distribution is commonly used to model a variety of natural phenomena and human characteristics due to its prevalence in the real world. Some examples include:\\n\\nHeight: The heights of individuals in a population tend to follow a normal distribution.\\nTest Scores: Test scores, IQ scores, and other measures of ability often approximate a normal distribution.\\nErrors in Measurement: Many measurement errors follow a normal distribution.\\nFinancial Data: Stock market returns and other financial variables often exhibit a normal distribution.\\nNatural Phenomena: Various natural phenomena like the distribution of particle velocities in a gas can be approximated by the normal distribution.\\nThe parameters of the normal distribution are the mean (μ) and the standard deviation (σ). The mean determines the center of the distribution, while the standard deviation controls the spread. A larger standard deviation results in a wider, more spread-out distribution.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3\n",
    "'''The normal distribution is commonly used to model a variety of natural phenomena and human characteristics due to its prevalence in the real world. Some examples include:\n",
    "\n",
    "Height: The heights of individuals in a population tend to follow a normal distribution.\n",
    "Test Scores: Test scores, IQ scores, and other measures of ability often approximate a normal distribution.\n",
    "Errors in Measurement: Many measurement errors follow a normal distribution.\n",
    "Financial Data: Stock market returns and other financial variables often exhibit a normal distribution.\n",
    "Natural Phenomena: Various natural phenomena like the distribution of particle velocities in a gas can be approximated by the normal distribution.\n",
    "The parameters of the normal distribution are the mean (μ) and the standard deviation (σ). The mean determines the center of the distribution, while the standard deviation controls the spread. A larger standard deviation results in a wider, more spread-out distribution.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The normal distribution is crucial in statistics and probability theory because of its mathematical properties and its widespread occurrence in nature. It's particularly important because of the Central Limit Theorem, which states that the distribution of the sum (or average) of a large number of independent, identically distributed random variables approaches a normal distribution, regardless of the original distribution.\\n\\nReal-life examples include:\\n\\n1.Quality Control: When manufacturing products, measurements such as length or weight often follow a normal distribution. This is useful for setting quality control standards.\\n2.Predictive Models: Many statistical and machine learning models assume that errors follow a normal distribution.\\n3.Hypothesis Testing: In hypothesis testing, the normal distribution is often used to determine critical values and p-values.\\n4.Process Analysis: It's used to analyze and improve various processes, from business operations to industrial processes.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4\n",
    "'''The normal distribution is crucial in statistics and probability theory because of its mathematical properties and its widespread occurrence in nature. It's particularly important because of the Central Limit Theorem, which states that the distribution of the sum (or average) of a large number of independent, identically distributed random variables approaches a normal distribution, regardless of the original distribution.\n",
    "\n",
    "Real-life examples include:\n",
    "\n",
    "1.Quality Control: When manufacturing products, measurements such as length or weight often follow a normal distribution. This is useful for setting quality control standards.\n",
    "2.Predictive Models: Many statistical and machine learning models assume that errors follow a normal distribution.\n",
    "3.Hypothesis Testing: In hypothesis testing, the normal distribution is often used to determine critical values and p-values.\n",
    "4.Process Analysis: It's used to analyze and improve various processes, from business operations to industrial processes.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Bernoulli Distribution describes a single trial with two possible outcomes: success (typically denoted as 1) or failure (typically denoted as 0). For example, flipping a coin, where heads could be considered a success and tails a failure.\\n\\nThe Binomial Distribution, on the other hand, models the number of successes in a fixed number of independent Bernoulli trials. It represents the number of successes in a fixed number of \"n\" trials. For example, the number of heads when flipping a coin 10 times.\\n\\nThe key difference is that Bernoulli deals with a single trial, while Binomial deals with multiple trials.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5\n",
    "'''The Bernoulli Distribution describes a single trial with two possible outcomes: success (typically denoted as 1) or failure (typically denoted as 0). For example, flipping a coin, where heads could be considered a success and tails a failure.\n",
    "\n",
    "The Binomial Distribution, on the other hand, models the number of successes in a fixed number of independent Bernoulli trials. It represents the number of successes in a fixed number of \"n\" trials. For example, the number of heads when flipping a coin 10 times.\n",
    "\n",
    "The key difference is that Bernoulli deals with a single trial, while Binomial deals with multiple trials.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To calculate the probability that a randomly selected observation from a normally distributed dataset with a mean of 50 and a standard deviation of 10 is greater than 60, you need to calculate the Z-score and then use the standard normal distribution table or calculator.\\n\\nThe Z-score formula is:\\nZ = (X - μ) / σ\\n\\nwhere X is the value (60 in this case), μ is the mean (50), and σ is the standard deviation (10).\\n\\nZ = (60 - 50) / 10 = 1\\n\\nNow, you can look up the probability of Z being greater than 1 from the standard normal distribution table. The area under the curve to the right of Z = 1 corresponds to the probability of a value being greater than 60.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6\n",
    "'''To calculate the probability that a randomly selected observation from a normally distributed dataset with a mean of 50 and a standard deviation of 10 is greater than 60, you need to calculate the Z-score and then use the standard normal distribution table or calculator.\n",
    "\n",
    "The Z-score formula is:\n",
    "Z = (X - μ) / σ\n",
    "\n",
    "where X is the value (60 in this case), μ is the mean (50), and σ is the standard deviation (10).\n",
    "\n",
    "Z = (60 - 50) / 10 = 1\n",
    "\n",
    "Now, you can look up the probability of Z being greater than 1 from the standard normal distribution table. The area under the curve to the right of Z = 1 corresponds to the probability of a value being greater than 60.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A uniform distribution is a probability distribution in which all possible outcomes are equally likely. In other words, each value within a specific range has the same probability of occurring. An example could be rolling a fair six-sided die, where each number has a probability of 1/6.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7\n",
    "'''A uniform distribution is a probability distribution in which all possible outcomes are equally likely. In other words, each value within a specific range has the same probability of occurring. An example could be rolling a fair six-sided die, where each number has a probability of 1/6.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Z-score, also known as the standard score, measures how many standard deviations a data point is away from the mean of a distribution. It's calculated as (X - μ) / σ, where X is the value, μ is the mean, and σ is the standard deviation. \\nThe Z-score is important because it allows you to compare and standardize values from different distributions. It's often used in hypothesis testing and to identify outliers.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q8\n",
    "'''The Z-score, also known as the standard score, measures how many standard deviations a data point is away from the mean of a distribution. It's calculated as (X - μ) / σ, where X is the value, μ is the mean, and σ is the standard deviation. \n",
    "The Z-score is important because it allows you to compare and standardize values from different distributions. It's often used in hypothesis testing and to identify outliers.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Central Limit Theorem states that the sum (or average) of a large number of independent, identically distributed random variables approaches a normal distribution,\\nregardless of the original distribution of the variables. This is crucial because it allows us to use normal distribution-based techniques even when dealing with non-normally distributed data, \\nas long as the sample size is large enough.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q9\n",
    "'''The Central Limit Theorem states that the sum (or average) of a large number of independent, identically distributed random variables approaches a normal distribution,\n",
    "regardless of the original distribution of the variables. This is crucial because it allows us to use normal distribution-based techniques even when dealing with non-normally distributed data, \n",
    "as long as the sample size is large enough.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The assumptions of the Central Limit Theorem include:\\n\\nIndependence: The random variables should be independent of each other.\\nIdentical Distribution: The variables should have the same distribution, regardless of whether it's normal or not.\\nSample Size: The larger the sample size, the better the normal approximation becomes. Generally, a sample size of 30 or more is considered sufficient for the CLT to hold.\\nFinite Variance: The variables should have a finite variance. If the variance is infinite, the CLT might not apply.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q10\n",
    "'''The assumptions of the Central Limit Theorem include:\n",
    "\n",
    "Independence: The random variables should be independent of each other.\n",
    "Identical Distribution: The variables should have the same distribution, regardless of whether it's normal or not.\n",
    "Sample Size: The larger the sample size, the better the normal approximation becomes. Generally, a sample size of 30 or more is considered sufficient for the CLT to hold.\n",
    "Finite Variance: The variables should have a finite variance. If the variance is infinite, the CLT might not apply.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
